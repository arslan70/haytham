# =============================================================================
# Haytham - Environment Variables
# Copy this file to .env and fill in your values:  cp .env.example .env
# =============================================================================

# -----------------------------------------------------------------------------
# LLM Provider (required)
# Options: bedrock, anthropic, openai, ollama
# Default: bedrock
# -----------------------------------------------------------------------------
LLM_PROVIDER=bedrock

# -----------------------------------------------------------------------------
# AWS Bedrock (required if LLM_PROVIDER=bedrock)
# Provide either AWS_PROFILE or AWS_REGION (with credentials configured)
# -----------------------------------------------------------------------------
AWS_PROFILE=
AWS_REGION=us-east-1

BEDROCK_REASONING_MODEL_ID=
BEDROCK_HEAVY_MODEL_ID=
BEDROCK_LIGHT_MODEL_ID=

# Bedrock timeouts (seconds)
# BEDROCK_READ_TIMEOUT=300.0
# BEDROCK_CONNECT_TIMEOUT=60.0

# -----------------------------------------------------------------------------
# Anthropic (required if LLM_PROVIDER=anthropic)
# -----------------------------------------------------------------------------
# ANTHROPIC_API_KEY=
# ANTHROPIC_REASONING_MODEL_ID=
# ANTHROPIC_HEAVY_MODEL_ID=
# ANTHROPIC_LIGHT_MODEL_ID=

# -----------------------------------------------------------------------------
# OpenAI (required if LLM_PROVIDER=openai)
# -----------------------------------------------------------------------------
# OPENAI_API_KEY=
# OPENAI_REASONING_MODEL_ID=
# OPENAI_HEAVY_MODEL_ID=
# OPENAI_LIGHT_MODEL_ID=

# -----------------------------------------------------------------------------
# Ollama (required if LLM_PROVIDER=ollama)
# -----------------------------------------------------------------------------
# OLLAMA_HOST=http://localhost:11434
# OLLAMA_REASONING_MODEL_ID=
# OLLAMA_HEAVY_MODEL_ID=
# OLLAMA_LIGHT_MODEL_ID=

# -----------------------------------------------------------------------------
# Agent settings
# -----------------------------------------------------------------------------
DEFAULT_MAX_TOKENS=5000
# ENABLE_FILE_CONTEXT=true

# -----------------------------------------------------------------------------
# Web search (optional, at least one key enables web search)
# -----------------------------------------------------------------------------
# BRAVE_API_KEY=
# TAVILY_API_KEY=
# WEB_SEARCH_SESSION_LIMIT=20

# -----------------------------------------------------------------------------
# Observability (optional)
# -----------------------------------------------------------------------------
LOG_LEVEL=INFO
OTEL_SDK_DISABLED=true
# OTEL_SERVICE_NAME=haytham-ai
# OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4317
# OTEL_TRACES_EXPORTER=otlp
# OTEL_TRACES_SAMPLER=always_on
# OTEL_TRACES_SAMPLER_ARG=1.0

# -----------------------------------------------------------------------------
# Langfuse tracing (optional)
# -----------------------------------------------------------------------------
# ENABLE_LANGFUSE=false
# LANGFUSE_PUBLIC_KEY=
# LANGFUSE_SECRET_KEY=
# LANGFUSE_HOST=https://cloud.langfuse.com
